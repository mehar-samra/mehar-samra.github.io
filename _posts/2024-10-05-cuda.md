## CUDA Development in Infiniworkflow

Whilst other node-based workflows exist currently, few utilize GPU-acceleration and complete parallel processing done aceoss all nodes. Integrating CUDA thus was a key task for the development of the application overall, and was my first task at Photron when I began full-time work. 

CUDA versions of existing nodes were implemented for both Image Processing and Correction, but the task of running image processing/correction code on the GPU involved more than simple edits to existing code. In fact, the majority of nodes had to be redone by hand in order to get the same output as non-GPU image correction nodes. 

In order to run code on the GPU, we need to create a kernel (as seen in the code below for a Brightness CUDA Node for float data).

```
__global__ void kernel_brightness32FC(CudaMat::Raster src, CudaMat::Raster dst, float brightnessB, float brightnessG, float brightnessR) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;

    if (x < dst.width && y < dst.height)
    {
        float* iT = (float*)(src.basePtr + x * src.numBytesPerPixel + y * src.rowbytes);
        float* oT = (float*)(dst.basePtr + x * dst.numBytesPerPixel + y * dst.rowbytes);

        float brightness[4] = { brightnessB , brightnessG , brightnessR , 1.f };

        for (int c = 0; c < dst.numChannels; ++c)
        {
            float value = static_cast<float>(iT[c]);
            value *= brightness[min(c, 4)];
            if (value > 1.0)
                value = 1.0;
            oT[c] = static_cast<float>(value);
        }
    }
}
```

However, several datatypes are available, not just CV_32F. These include CV_8U, CV_8S, CV_16U, and CV_16S. In order to prevent ugly, repeat code, we utilized templatized code for all kernels across the many CUDA nodes available. This means users can swap between data types of unsigned ints to floats seemlessly, all whilst the templatized code takes care of all conversions.



