## OpenGL Learning Updates

Working on implementing Pyrender into Infiniworkflow has now led me to investigate other ways of performing rendering and having 3D graphics control, including exploring OpenGL further.

OpenGL is a cross-platform API for performing 2D and 3D rendering, and as such is most commonly used open graphics standard today. OpenGL is a fairly old API, so there is an 'old' way of using OpenGL and a 'new' way. The 'old' way is usually referred to as a fixed function pipeline, whereas the 'new' way is a more programmatic pipeline that allows for greater control and performance for rendering. The programmatic way, while powerful, is quite difficult to learn without any prior knowledge of the API. Hence, during my learning, I have opted to start with the old method and work my way incrementally towards the current, programmatic approach.

OpenGL is cross-platform, but the way of creating a rendering viewer varies from platform to platform. As such, we use libraries such as GLFW or GLUT to ensure that our code works across all platforms by abstracting away all of the details on creating a viewer. (For this post I used GLFW.)

Once you use GLFW to create and set your viewing window, this is the most barebone version of the code needed to render a 2D object in a scene using the fixed function approach:

```
	glBegin(GL_TRIANGLES)

	glColor3f(1.0, 0.0, 0.0)

    glVertex3f(-0.5, -0.5, 0.0)  # Vertex 1
    glVertex3f(0.5, -0.5, 0.0)   # Vertex 2
    glVertex3f(0.0, 0.5, 0.0)    # Vertex 3

    glEnd()
```

This code will live inside a while loop that checks whether the viewer should be opened or closed. If we break down this code, we see glBegin() and glEnd() bookend the other code responsible for creating an object, which in this case is a red triangle. Note that if we wanted the triangle to be multicolored, we could set glColor3f() before each glVertex3f() call, and that if we wanted to render something other than a triangle (such as a Quad or a Polygon), we could do so by changing the input to glBegin() (which is a PrimitiveType) and adjusting the number of vertices created.

Further, note that if we do set a color per vertex, the triangle becomes a Gouraud-shaded triangle, wherein each pixel within the triangle is a linear interpolation between the 3 different vertex colors; this means that for a triangle with red, green, and blue colored vertices, respectively, pixels close to the red vertex will be shaded more red, pixels close to the green vertex will be shaded more green, and pixels in the very middle of the triangle will be a mix of red, green, and blue.

Beyond this, we can begin giving 2D objects textures by loading in a texture image, and then setting the U,V coordinate on the texture image for its associated vertex in the rendered scene (instead of setting glColor3f() for each vertex, we will instead set glTexCoord2f() for each vertex).

Perhaps the most complicated part of using the fixed function pipeline approach (in my opinion) is setting and controlling the lighting in a scene. Within a scene, there can be many different types of light, including Ambient, Diffuse, and Spectral. Ambient light is just general light that exists without direction. Diffuse light has a direction but the light rays that hit an object reflect equally in all directions (such as how light reflects off of a wool shirt). Spectral light, on the other hand, has a direction and reflects in a particular way, in the same way that light reflects off of a shiny metal surface. As such, the direction and position of the camera is important to Spectral light, whereas the camera can be anywhere as far as Ambient and Diffuse light are concerned when it comes to calculating the values of light that reflect off each object.

This is just the barebones of what I've learned in OpenGL so far, as I still have yet to describe how we can begin incorporating elements of the programmatic approach into our rendering calculations/code.

